[2025-06-09T19:07:41.541+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-06-09T19:07:41.559+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: 05_transform_data.run_dbt manual__2025-06-09T19:07:32.078331+00:00 [queued]>
[2025-06-09T19:07:41.568+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: 05_transform_data.run_dbt manual__2025-06-09T19:07:32.078331+00:00 [queued]>
[2025-06-09T19:07:41.569+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 1
[2025-06-09T19:07:41.584+0000] {taskinstance.py:2889} INFO - Executing <Task(PythonOperator): run_dbt> on 2025-06-09 19:07:32.078331+00:00
[2025-06-09T19:07:41.589+0000] {standard_task_runner.py:72} INFO - Started process 223 to run task
[2025-06-09T19:07:41.592+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', '05_transform_data', 'run_dbt', 'manual__2025-06-09T19:07:32.078331+00:00', '--job-id', '506', '--raw', '--subdir', 'DAGS_FOLDER/05_transform_data.py', '--cfg-path', '/tmp/tmp85jokyli']
[2025-06-09T19:07:41.593+0000] {standard_task_runner.py:105} INFO - Job 506: Subtask run_dbt
[2025-06-09T19:07:41.652+0000] {task_command.py:467} INFO - Running <TaskInstance: 05_transform_data.run_dbt manual__2025-06-09T19:07:32.078331+00:00 [running]> on host 28e6a58e4107
[2025-06-09T19:07:41.744+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='05_transform_data' AIRFLOW_CTX_TASK_ID='run_dbt' AIRFLOW_CTX_EXECUTION_DATE='2025-06-09T19:07:32.078331+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-06-09T19:07:32.078331+00:00'
[2025-06-09T19:07:41.746+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-06-09T19:07:43.357+0000] {logging_mixin.py:190} INFO - 19:07:43  Running with dbt=1.9.5
[2025-06-09T19:07:43.773+0000] {logging_mixin.py:190} INFO - 19:07:43  Registered adapter: postgres=1.9.0
[2025-06-09T19:07:45.080+0000] {logging_mixin.py:190} INFO - 19:07:45  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.e_commerce_sales.example
[2025-06-09T19:07:45.455+0000] {logging_mixin.py:190} INFO - 19:07:45  Found 15 models, 12 sources, 549 macros, 1 unit test
[2025-06-09T19:07:45.460+0000] {logging_mixin.py:190} INFO - 19:07:45
[2025-06-09T19:07:45.461+0000] {logging_mixin.py:190} INFO - 19:07:45  Concurrency: 4 threads (target='dev')
[2025-06-09T19:07:45.463+0000] {logging_mixin.py:190} INFO - 19:07:45
[2025-06-09T19:07:45.601+0000] {logging_mixin.py:190} INFO - 19:07:45  1 of 15 START sql incremental model sales.mercadolivre_orders_results .......... [RUN]
[2025-06-09T19:07:45.602+0000] {logging_mixin.py:190} INFO - 19:07:45  2 of 15 START sql incremental model sales.stg_shopee ........................... [RUN]
[2025-06-09T19:07:45.974+0000] {logging_mixin.py:190} INFO - 19:07:45  2 of 15 OK created sql incremental model sales.stg_shopee ...................... [MERGE 0 in 0.36s]
[2025-06-09T19:07:45.981+0000] {logging_mixin.py:190} INFO - 19:07:45  3 of 15 START sql incremental model sales.shopee_new_id ........................ [RUN]
[2025-06-09T19:07:45.983+0000] {logging_mixin.py:190} INFO - 19:07:45  4 of 15 START sql incremental model sales.shopee_orders_results ................ [RUN]
[2025-06-09T19:07:46.082+0000] {logging_mixin.py:190} INFO - 19:07:46  4 of 15 ERROR creating sql incremental model sales.shopee_orders_results ....... [ERROR in 0.09s]
[2025-06-09T19:07:46.099+0000] {logging_mixin.py:190} INFO - 19:07:46  5 of 15 SKIP relation sales.dim_shopee_buyer ................................... [SKIP]
[2025-06-09T19:07:46.101+0000] {logging_mixin.py:190} INFO - 19:07:46  6 of 15 SKIP relation sales.dim_shopee_date .................................... [SKIP]
[2025-06-09T19:07:46.111+0000] {logging_mixin.py:190} INFO - 19:07:46  7 of 15 SKIP relation sales.dim_shopee_orders_status ........................... [SKIP]
[2025-06-09T19:07:46.117+0000] {logging_mixin.py:190} INFO - 19:07:46  8 of 15 SKIP relation sales.dim_shopee_product ................................. [SKIP]
[2025-06-09T19:07:46.125+0000] {logging_mixin.py:190} INFO - 19:07:46  9 of 15 SKIP relation sales.sum_shopee_monthly_profit .......................... [SKIP]
[2025-06-09T19:07:46.126+0000] {logging_mixin.py:190} INFO - 19:07:46  10 of 15 SKIP relation sales.sum_shopee_monthly_revenue ........................ [SKIP]
[2025-06-09T19:07:46.134+0000] {logging_mixin.py:190} INFO - 19:07:46  11 of 15 SKIP relation sales.sum_shopee_products_sold .......................... [SKIP]
[2025-06-09T19:07:46.148+0000] {logging_mixin.py:190} INFO - 19:07:46  3 of 15 OK created sql incremental model sales.shopee_new_id ................... [MERGE 0 in 0.16s]
[2025-06-09T19:07:48.763+0000] {logging_mixin.py:190} INFO - 19:07:48  1 of 15 OK created sql incremental model sales.mercadolivre_orders_results ..... [MERGE 190 in 3.16s]
[2025-06-09T19:07:48.771+0000] {logging_mixin.py:190} INFO - 19:07:48  12 of 15 START sql incremental model sales.dim_mercadolivre_buyer .............. [RUN]
[2025-06-09T19:07:48.773+0000] {logging_mixin.py:190} INFO - 19:07:48  13 of 15 START sql incremental model sales.dim_mercadolivre_date ............... [RUN]
[2025-06-09T19:07:48.775+0000] {logging_mixin.py:190} INFO - 19:07:48  14 of 15 START sql incremental model sales.dim_mercadolivre_orders_status ...... [RUN]
[2025-06-09T19:07:48.777+0000] {logging_mixin.py:190} INFO - 19:07:48  15 of 15 START sql incremental model sales.dim_mercadolivre_product ............ [RUN]
[2025-06-09T19:07:49.033+0000] {logging_mixin.py:190} INFO - 19:07:49  14 of 15 OK created sql incremental model sales.dim_mercadolivre_orders_status . [MERGE 190 in 0.25s]
[2025-06-09T19:07:49.051+0000] {logging_mixin.py:190} INFO - 19:07:49  12 of 15 OK created sql incremental model sales.dim_mercadolivre_buyer ......... [MERGE 188 in 0.27s]
[2025-06-09T19:07:51.287+0000] {logging_mixin.py:190} INFO - 19:07:51  13 of 15 OK created sql incremental model sales.dim_mercadolivre_date .......... [MERGE 190 in 2.51s]
[2025-06-09T19:07:53.486+0000] {logging_mixin.py:190} INFO - 19:07:53  15 of 15 OK created sql incremental model sales.dim_mercadolivre_product ....... [MERGE 65 in 4.70s]
[2025-06-09T19:07:53.512+0000] {logging_mixin.py:190} INFO - 19:07:53
[2025-06-09T19:07:53.514+0000] {logging_mixin.py:190} INFO - 19:07:53  Finished running 12 incremental models, 3 view models in 0 hours 0 minutes and 8.05 seconds (8.05s).
[2025-06-09T19:07:53.602+0000] {logging_mixin.py:190} INFO - 19:07:53
[2025-06-09T19:07:53.603+0000] {logging_mixin.py:190} INFO - 19:07:53  Completed with 1 error, 0 partial successes, and 0 warnings:
[2025-06-09T19:07:53.606+0000] {logging_mixin.py:190} INFO - 19:07:53
[2025-06-09T19:07:53.608+0000] {logging_mixin.py:190} INFO - 19:07:53    Database Error in model shopee_orders_results (models/core/shopee_orders_results.sql)
  syntax error at or near "."
  LINE 20: ...         stg_shopee.load_timestamp AS id_buyer_sku.load_time...
                                                                ^
  compiled code at target/run/e_commerce_sales/models/core/shopee_orders_results.sql
[2025-06-09T19:07:53.609+0000] {logging_mixin.py:190} INFO - 19:07:53
[2025-06-09T19:07:53.611+0000] {logging_mixin.py:190} INFO - 19:07:53  Done. PASS=7 WARN=0 ERROR=1 SKIP=7 TOTAL=15
[2025-06-09T19:07:55.646+0000] {logging_mixin.py:190} INFO - dbt run failed!
[2025-06-09T19:07:55.648+0000] {logging_mixin.py:190} INFO - None
[2025-06-09T19:07:55.649+0000] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 422, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/opt/airflow/dbt_files/run_dbt.py", line 22, in transform_data
    raise RuntimeError("dbt run failed")
RuntimeError: dbt run failed
[2025-06-09T19:07:55.662+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=05_transform_data, task_id=run_dbt, run_id=manual__2025-06-09T19:07:32.078331+00:00, execution_date=20250609T190732, start_date=20250609T190741, end_date=20250609T190755
[2025-06-09T19:07:55.680+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-06-09T19:07:55.682+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 506 for task run_dbt (dbt run failed; 223)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 422, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/opt/airflow/dbt_files/run_dbt.py", line 22, in transform_data
    raise RuntimeError("dbt run failed")
RuntimeError: dbt run failed
[2025-06-09T19:07:55.733+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-06-09T19:07:55.760+0000] {taskinstance.py:3895} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-06-09T19:07:55.763+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
